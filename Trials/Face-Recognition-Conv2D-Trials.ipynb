{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e92aa-0ade-41d1-a8f1-c73cca1d8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "import wandb \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bcd56-b107-404e-b303-a1cb152c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU \\n\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660e6e2-27d5-44ad-b1b1-30626548d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306bfa8-e88f-45f1-adbb-9a0e60e0abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14dc79-fd98-4f41-aab7-75d5202d01ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (160, 160))\n",
    "    return img, label\n",
    "\n",
    "def make_dataset(paths, labels, batch_size = 32, shuffle = False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1e043d-3f70-4435-b102-d28b7cf6b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "# Se debe de realizar una transformaci√≥n en los datos, haciendo que todas las identidades sean 0:\n",
    "\n",
    "ds = pd.read_csv(\"/tf/Face-Recognition/CelebA/identity_CelebA.txt\", sep = r\"\\s+\", names=[\"image\", \"identity\"])\n",
    "\n",
    "ds[\"identity\"] = 0\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1e1f7-10ec-4230-8a98-92d43f9cb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = \"/tf/Face-Recognition/CelebA/img_align_celeba\"\n",
    "\n",
    "# ds[\"image_path\"] = ds[\"image\"].apply(lambda x: os.path.join(img_dir, x))\n",
    "ds = ds.sample(4000, random_state = 4).reset_index(drop = True)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099fe841-d3c2-47b0-acb9-84d683e29975",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array([])\n",
    "identity = np.zeros(40)\n",
    "\n",
    "for i in range(40):\n",
    "    image = np.append(image, f\"me{i+1}.jpg\")\n",
    "    identity[i] = 1\n",
    "\n",
    "identity = identity.astype(int)\n",
    "\n",
    "# print(image)\n",
    "# print(identity)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"image\": image,\n",
    "    \"identity\": identity,\n",
    "})\n",
    "\n",
    "# me_dir = \"/tf/Face-Recognition/CelebA/Me\"\n",
    "# df[\"image_path\"] = df[\"image\"].apply(lambda x: os.path.join(me_dir, x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3dc55-7674-4b3c-ba0d-689b3161a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.concat([ds, df], axis = 0)\n",
    "ds = ds.sample(frac = 1, random_state = 5).reset_index(drop = True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909413ad-31e4-44bf-815d-aa1b7945f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_temp = train_test_split(\n",
    "    ds, test_size = 0.2, stratify = ds[\"identity\"], random_state = 5)\n",
    "\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp, test_size = 0.5, stratify = df_temp[\"identity\"], random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16aa5a-30ea-4a9e-8fcd-b84302c5d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"identity\"].value_counts())\n",
    "print(df_val[\"identity\"].value_counts())\n",
    "print(df_test[\"identity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0980521-d151-4853-8ace-9e485108936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base = \"binary_faces\"\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(f\"{base}/{split}/me\", exist_ok = True)\n",
    "    os.makedirs(f\"{base}/{split}/others\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953cc9b0-c4b3-44df-b585-d14e8b62e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(df, split):\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"identity\"] == 1:\n",
    "            src = os.path.join(\"/tf/Face-Recognition/CelebA/Me\", row[\"image\"])\n",
    "            dst = f\"{base}/{split}/me/{row['image']}\"\n",
    "        else:\n",
    "            src = os.path.join(\"/tf/Face-Recognition/CelebA/img_align_celeba\", row[\"image\"])\n",
    "            dst = f\"{base}/{split}/others/{row['image']}\"\n",
    "        \n",
    "        shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265fa8d-ac10-4cd3-bf23-e2f146a3ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(df_train, \"train\")\n",
    "copy_files(df_val, \"val\")\n",
    "copy_files(df_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00830cf-b215-464f-a3cb-dedf7936f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_val_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac4e71-393a-4d2e-8865-f8997e6341b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_datagen.flow_from_directory(\n",
    "    f\"{base}/train\",\n",
    "    target_size = (160,160),\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = 32,\n",
    "    seed = 4)\n",
    "\n",
    "val = test_val_datagen.flow_from_directory(\n",
    "    f\"{base}/val\",\n",
    "    target_size = (160,160),\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = 32,\n",
    "    seed = 4)\n",
    "\n",
    "test = test_val_datagen.flow_from_directory(\n",
    "    f\"{base}/test\",\n",
    "    target_size = (160,160),\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = 32,\n",
    "    seed = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e936b8-97a9-4ae3-a215-62c78ae486fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureExtractor = tf.keras.models.load_model(\"/tf/Face-Recognition/Models/Conv2D-MobileNetV2-Based-Fine-Tunned.keras\")\n",
    "FeatureExtractor.trainable = False\n",
    "\n",
    "FeatureExtractor_Output = FeatureExtractor.layers[-3].output\n",
    "FeatureExtractor_Model = tf.keras.Model(FeatureExtractor.input, FeatureExtractor_Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebd21c-c9b9-4938-a463-24d9c49913c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8960052d-3dcb-4829-bf7e-3ced08b451cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160,160,3))\n",
    "x = FeatureExtractor_Model(inputs, training = False)\n",
    "x = tf.keras.layers.Dense(256, activation=\"leaky_relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation = \"leaky_relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.15)(x)\n",
    "x = tf.keras.layers.Dense(64, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation = \"sigmoid\", dtype = \"float32\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\",\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe1459-9ad0-4dc1-8020-1531a74a6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = \"val_accuracy\", patience = 10, restore_best_weights = True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9a782-c535-445e-9387-637ec01750ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "        project = \"Face-Recognition-Conv2D-Trials-Exp-Series1.0\",\n",
    "        name = \"Trial_1_FullSet\",\n",
    "        reinit = True,\n",
    "        config = {\n",
    "            \"activation\": \"leaky_relu, relu\",\n",
    "            \"n_layers\": 3,\n",
    "            \"learning_rate\": lr,\n",
    "            \"optimizer\": \"RMSProp\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e90a9-0877-4d03-866b-32457e790e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train, \n",
    "    validation_data = val,\n",
    "    epochs = 200,\n",
    "    verbose = 1, \n",
    "    callbacks = [WandbMetricsLogger(log_freq = 5), early_stopping, lr_reduction]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97489d8-b393-40a5-889b-1cf6b73c3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Face-Recognition-Conv2D.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fe355-9149-4ee9-aa38-bd1570f6cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "wandb.finish()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
