{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798c53a-fc5c-4b53-9fb2-d7484a22eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from tensorflow.keras import regularizers, models, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144803d9-0801-49a2-b75a-a185fab78904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc921e-872d-4b6e-aa27-ee13c405446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU \\n\", gpus)\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c655ac-7718-4ae5-b602-a7a9aa608eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4b38a-c3a4-4887-a1af-c694bcca9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "\n",
    "wandb.require(\"core\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40477d80-dd7c-4131-95c0-efc4567b2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan los datos\n",
    "# Se debe de realizar una transformación en los datos, convirtiéndolos de -1/1 a 0/1:\n",
    "\n",
    "\n",
    "ds = pd.read_csv(\"/tf/Face-Recognition/CelebA/list_attr_celeba.txt\", sep = r\"\\s+\", skiprows = 1)\n",
    "ds.iloc[:, 0:39] = (ds.iloc[:, 0:39] == 1).astype(\"int32\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08f074-3a6d-4578-9024-80b32198918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"/img_align_celeba\"\n",
    "\n",
    "ds[\"image_path\"] = ds.index.map(lambda x: os.path.join(img_dir, x))\n",
    "ds.reset_index(inplace = True)\n",
    "ds.rename(columns = {\"index\" : \"image\"}, inplace = True)\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a450745-506b-4b9d-8e56-c05458194e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv(\n",
    "    \"/tf/Face-Recognition/CelebA/Eval/list_eval_partition.txt\", \n",
    "    sep = r\"\\s+\",\n",
    "    names = [\"image\", \"partition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd122b64-036d-4b11-a02b-b010f0537f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.merge(df_split, on = \"image\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da3f18-2b3c-4130-a2b3-d83ee7814b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ds[ds[\"partition\"] == 0]\n",
    "df_val   = ds[ds[\"partition\"] == 1]\n",
    "df_test  = ds[ds[\"partition\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e083eacf-1609-4fca-be2f-ccfde1f30397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (128, 128))\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "def make_dataset(paths, labels, batch_size = 32, shuffle = False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10000)\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c28e8-639b-4f51-99ef-ac89e77708d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(\n",
    "    df_train[\"image_path\"].values, \n",
    "    df_train.iloc[:, 1:41].values,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_ds = make_dataset(\n",
    "    df_val[\"image_path\"].values,\n",
    "    df_val.iloc[:, 1:41].values,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_ds = make_dataset(\n",
    "    df_test[\"image_path\"].values,\n",
    "    df_test.iloc[:, 1:41].values,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e1663-6c59-48ca-af92-40556aeca459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_small = df_train.sample(frac = 0.05, random_state = 5)\n",
    "df_val_small = df_val.sample(frac = 0.05, random_state = 5)\n",
    "df_test_small = df_test.sample(frac = 0.05, random_state = 5)\n",
    "\n",
    "train_ds_small = make_dataset(\n",
    "    df_train_small[\"image_path\"].values,\n",
    "    df_train_small.iloc[:, 1:41].values,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "val_ds_small = make_dataset(\n",
    "    df_val_small[\"image_path\"].values,\n",
    "    df_val_small.iloc[:, 1:41].values,\n",
    ")\n",
    "\n",
    "test_ds_small = make_dataset(\n",
    "    df_test_small[\"image_path\"].values,\n",
    "    df_test_small.iloc[:, 1:41].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6dc8af-932e-4f2a-9085-e2fe4c303c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "print(\"JPEG files:\", len(glob.glob(\"/img_align_celeba/*.jpg\")))\n",
    "print(\"PNG files:\", len(glob.glob(\"/img_align_celeba/*.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b4536-e232-4302-9e56-1d1c4ee34001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para los bloques residuales\n",
    "\n",
    "def residual_block(x, kernel, kernel_size, activation, dropout, dropout_rate, regularizer, r_2):\n",
    "        \n",
    "    residual = x  \n",
    "        \n",
    "    if dropout == \"y\":\n",
    "        # Camino \"principal\"\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                          activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Capa intermedia Dropot\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "            \n",
    "        # Capa lineal\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                          kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "            \n",
    "    else: \n",
    "        # Camino \"principal\"\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                          activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "                \n",
    "        # Capa lineal\n",
    "        x = layers.Conv2D(kernel, (kernel_size, kernel_size), padding = \"same\",\n",
    "                          kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Suma de la conexión residual\n",
    "    x = layers.add([x, residual]) \n",
    "    x = layers.Activation(activation)(x)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99918665-9a72-485d-b411-c1978dda1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    inputs = layers.Input(shape = (256, 256, 3))\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    # Optuna sugiere función de activación para todas las capas\n",
    "    activation = trial.suggest_categorical(f\"activation_L{i+2}\", [\"relu\", \"relu6\", \"leaky_relu\"])\n",
    "    \n",
    "    # Optuna sugiere regularizador\n",
    "    regularizer = \"L2\"\n",
    "    r_2 = 0.0 # trial.suggest_float(\"regularizer_value_2\", 1e-7, 1e-5, log = True)\n",
    "    \n",
    "    # Optuna sugiere el número de capas\n",
    "    n_layers = 4 # trial.suggest_int(\"N_layers\", 15,20)\n",
    "    \n",
    "    # Optuna sugiere número de kernels y su tamaño en la primer capa convolucional\n",
    "    \n",
    "    kernel_1 = 8\n",
    "    size_1 = 2\n",
    "    \n",
    "    # Optuna sugiere Learning Rate y Optimizador\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", 2.5e-4, 1e-3, log = True)\n",
    "    \n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"adam\", \"rmsprop\"])\n",
    "    \n",
    "                              \n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "                              \n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr)               \n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    # Primera convolución\n",
    "    \n",
    "    x = layers.Conv2D(kernel_1, (size_1,size_1), padding = \"same\")(inputs)\n",
    "    x = layers.Activation(activation)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    kernel_per_layer = [kernel_1]\n",
    "    kernel_size_per_layer = [size_1]\n",
    "    \n",
    "    # Optuna sugiere número de kernels su tamaño y función de activación; también sugiere Dropout\n",
    "    # y regularizadores\n",
    "    \n",
    "    dropout_per_layer = []\n",
    "    dropout_percentage_per_layer = []\n",
    "    \n",
    "    n_kernel =  16\n",
    "    \n",
    "    kernel_size = 3\n",
    "    \n",
    "    kernel_size_per_layer.append(kernel_size)\n",
    "    dropping_out = \"n\" # trial.suggest_categorical(\"Dropout\", [\"y\", \"n\"])\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "                              \n",
    "        dropout = trial.suggest_categorical(f\"Dropout_L{i+2}\", [\"y\", \"n\"])\n",
    "        dropout_per_layer.append(dropout)\n",
    "                              \n",
    "        dropout_rate = trial.suggest_float(f\"Dropout_value_L{i+2}\",0.1, 0.15)\n",
    "        \n",
    "        # Capa Convolucional i-ésima:\n",
    "        \n",
    "        # Se elige entre Dropout o un Regularizador\n",
    "        \n",
    "        if dropping_out == \"y\":\n",
    "            \n",
    "            if dropout == \"y\":\n",
    "            \n",
    "                dropout_percentage_per_layer.append(dropout_rate)\n",
    "\n",
    "                ker = int(n_kernel*2**(i))\n",
    "                kernel_per_layer.append(ker)\n",
    "\n",
    "                x = layers.Conv2D(ker, (kernel_size, kernel_size), strides = 2, padding = \"same\",\n",
    "                                  activation = activation)(x)\n",
    "                x = layers.BatchNormalization()(x)\n",
    "                x = residual_block(x, ker, kernel_size, activation, dropout, dropout_rate, regularizer, r_2)\n",
    "                \n",
    "                number = trial.suggest_int(f\"Layers_{i}\", 1, 2)\n",
    "                \n",
    "                for k in range (number): \n",
    "                    ker2 = ker*(1**k)\n",
    "                    \n",
    "                    x = layers.Conv2D(ker2, (kernel_size, kernel_size), padding = \"same\",\n",
    "                                      activation = activation)(x)\n",
    "                    x = layers.BatchNormalization()(x)\n",
    "                    x = residual_block(x, ker2, kernel_size, activation, dropout, dropout_rate, regularizer, r_2)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                dropout_percentage_per_layer.append(0.0)\n",
    "\n",
    "                ker = int(n_kernel*2**(i))\n",
    "                kernel_per_layer.append(ker)\n",
    "                \n",
    "                number = trial.suggest_int(f\"Layers_{i}\", 1, 2)\n",
    "\n",
    "                x = layers.Conv2D(ker, (kernel_size, kernel_size), strides = 2, padding = \"same\",\n",
    "                                  activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "                x = layers.BatchNormalization()(x)\n",
    "                x = residual_block(x, ker, kernel_size, activation, dropout, dropout_rate, regularizer, r_2)\n",
    "                \n",
    "                for k in range (number): \n",
    "                    ker2 = ker*(1**k)\n",
    "                \n",
    "                    x = layers.Conv2D(ker2, (kernel_size, kernel_size), padding = \"same\",\n",
    "                                      activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "                    x = layers.BatchNormalization()(x)\n",
    "                    x = residual_block(x, ker2, kernel_size, activation, dropout, dropout_rate, regularizer, r_2)\n",
    "            \n",
    "        else:\n",
    "            dropout_percentage_per_layer.append(0.0)\n",
    "\n",
    "            ker = int(n_kernel*2**(i))\n",
    "            kernel_per_layer.append(ker)\n",
    "\n",
    "            x = layers.Conv2D(ker, (kernel_size, kernel_size), strides = 2, padding = \"same\",\n",
    "                              activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = residual_block(x, ker, kernel_size, activation, \"n\", dropout_rate, regularizer, r_2)\n",
    "            \n",
    "            number = trial.suggest_int(f\"Layers_{i}\", 1, 2)\n",
    "            \n",
    "            for k in range (number):\n",
    "                \n",
    "                ker2 = ker*(1**k)\n",
    "                \n",
    "                x = layers.Conv2D(ker2, (kernel_size, kernel_size), padding = \"same\",\n",
    "                                  activation = activation, kernel_regularizer = regularizers.l2(r_2))(x)\n",
    "                x = layers.BatchNormalization()(x)\n",
    "                x = residual_block(x, ker2, kernel_size, activation, \"n\", dropout_rate, regularizer, r_2)\n",
    "            \n",
    "            x = layers.Dropout(0.10)(x)\n",
    "            \n",
    "            \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "                              \n",
    "    outputs = layers.Dense(4, activation = \"softmax\", dtype = \"float32\")(x)\n",
    "        \n",
    "    model = models.Model(inputs, outputs)\n",
    "                              \n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = \"categorical_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])\n",
    "    \n",
    "    #############################################################################################################\n",
    "\n",
    "    wandb.init(\n",
    "        project = \"Conv2D-Residual-Trials-ExpSeries1.0\",\n",
    "        name = f\"Trial_{trial.number}\",\n",
    "        reinit = True,\n",
    "        config = {\n",
    "            \"kernel_1\": kernel_1,\n",
    "            \"size_1\": size_1,\n",
    "            \"activation\": activation,\n",
    "            \"n_layers\": n_layers,\n",
    "            \"n_kernel\": n_kernel,\n",
    "            \"kernel_size\": kernel_size,\n",
    "            \"kernel_per_layer\": kernel_per_layer,\n",
    "            \"kernel_size_per_layer\": kernel_size_per_layer,\n",
    "            \"regularizer\": regularizer,\n",
    "            \"r_value2\": r_2,\n",
    "            \"Dropout\": dropping_out, \n",
    "            \"dropout_per_layer\": dropout_per_layer,\n",
    "            \"dropout_percentage_per_layer\": dropout_percentage_per_layer,\n",
    "            \"learning_rate\": lr,\n",
    "            \"optimizer\": activation,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    \"\"\"\n",
    "    Callbacks\n",
    "    \"\"\"\n",
    "    early_stopping = EarlyStopping(monitor = \"val_accuracy\", patience = 10, restore_best_weights = True)\n",
    "    lr_reduction = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 7)\n",
    "#     tensorboard_cb = TensorBoard(log_dir = \"/workspace/Optuna-Trials/Plant-Pathology-Classificator/tf_debug\", histogram_freq = 1, write_graph = True,\n",
    "#                                  write_images = False)\n",
    "    \n",
    "    #############################################################################################################\n",
    "    \n",
    "    \"\"\"\n",
    "    Creación del modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(model.summary())\n",
    "    \n",
    "        history = model.fit(\n",
    "            train_ds_small, \n",
    "            validation_data = val_ds_small,\n",
    "            epochs = 200,\n",
    "            verbose = 1, \n",
    "            callbacks = [WandbMetricsLogger(log_freq = 5), early_stopping, lr_reduction]\n",
    "        )\n",
    "\n",
    "        val_loss = min(history.history[\"val_loss\"])\n",
    "        val_accuracy = max(history.history[\"val_accuracy\"])\n",
    "        \n",
    "        train_loss = min(history.history[\"loss\"])\n",
    "        train_accuracy = max(history.history[\"accuracy\"])\n",
    "    \n",
    "    except tf.errors.ResourceExhaustedError as e:\n",
    "        \n",
    "        print(f\"Intento {trial.number} falló debido a: {e}\")\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        wandb.finish()\n",
    "        gc.collect()\n",
    "        \n",
    "        return float(\"inf\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Intento {trial.number} falló. Unexpected error: {e}\")\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        wandb.finish()\n",
    "        gc.collect()\n",
    "        \n",
    "        return float(\"inf\")\n",
    "    \n",
    "    # score = val_loss + 0.1 * (train_loss - val_loss)\n",
    "    \n",
    "    score = val_accuracy\n",
    "    \n",
    "    # score = train_loss \n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    wandb.finish()\n",
    "\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52c86b-2381-4abf-be9e-f881b9a169bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name = \"Conv2D-Residual-Trials-ExpSeries1.0\",\n",
    "    direction = \"minimize\",\n",
    "    storage = \"sqlite:////workspace/Optuna-Trials/Conv2D-Residual-Trials-ExpSeries1.0_study.db\",\n",
    "    load_if_exists = True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials = 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
